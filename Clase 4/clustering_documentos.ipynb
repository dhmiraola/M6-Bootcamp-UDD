{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jx9t65_PwW5"
   },
   "source": [
    "**CLUSTERING DE DOCUMENTOS**\n",
    "\n",
    "\n",
    "\n",
    "Este programa permite realizar clustering (agrupación) del tipo K-Means de documentos a partir de un corpus. Los documentos se representan según los modelos vectoriales estándares.\n",
    "\n",
    "Primero, necesitamos instalar algunos paquetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0VBw9k8Pptm"
   },
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "# !python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIBN4pczQLC3"
   },
   "source": [
    "Debemos importar algunas bibliotecas y utilitarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Roihnh0gQYWY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import MDS\n",
    "import es_core_news_sm\n",
    "import os\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import regex\n",
    "from string import punctuation\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvmY4uDzQvyK"
   },
   "source": [
    "Re-utilizamos nuestra función **CrearVSM(textos,nombreModelo)** que permite crear un modelo vectorial \n",
    "simple del tipo TFxIDF y grabarlo para posterior uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSRj1vecQ1uq"
   },
   "outputs": [],
   "source": [
    "def CrearVSM(textos,nombreModelo):\n",
    "  modelo  = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
    "  matriz_features  = modelo.fit_transform(textos)\n",
    "  vocabulario      = modelo.vocabulary_\n",
    "  dtm              = matriz_features.toarray()\n",
    "  GrabarModelo(nombreModelo,dtm,vocabulario)\n",
    "  \n",
    "def GrabarModelo(NombreModelo,vectores,vocab):\n",
    "   existe = os.path.isdir(NombreModelo)\n",
    "   if not existe:\n",
    "       os.mkdir(NombreModelo)\n",
    "   joblib.dump(vectores, NombreModelo +\"/\"+'tfidf.pkl') \n",
    "   joblib.dump(vocab, NombreModelo +\"/\"+'vocab.pkl') \n",
    "  \n",
    "def CargarModelo(NombreModelo):\n",
    "    vectores = joblib.load(NombreModelo+\"/\"+'tfidf.pkl')\n",
    "    vocab  = joblib.load(NombreModelo+\"/\"+'vocab.pkl')\n",
    "    return(vectores,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP4WPBrIRlVJ"
   },
   "source": [
    "Ahora, re-usamos algunas funciones utilitarias definidas previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoLL8TxWRp2h"
   },
   "outputs": [],
   "source": [
    "def CrearCorpus(path):\n",
    "  directorio = os.listdir(path)\n",
    "  corpus = []\n",
    "  doc_id = []  \n",
    "  for filename  in directorio:\n",
    "     texto = open(path+filename,'r',encoding=\"latin-1\").read()\n",
    "     texto = ConvertirAcentos(texto)\n",
    "     corpus.append(texto)\n",
    "     doc_id.append(filename)\n",
    "  return(corpus,doc_id)\n",
    "\n",
    "def ConvertirAcentos(texto):\n",
    "    texto=texto.replace(\"\\xc3\\xa1\",\"á\")\n",
    "    texto=texto.replace(\"\\xc3\\xa9\",\"é\")   \n",
    "    texto=texto.replace(\"\\xc3\\xad\",\"í\")\n",
    "    texto=texto.replace(\"\\xc3\\xb3\",\"ó\")\n",
    "    texto=texto.replace(\"\\xc3\\xba\",\"ú\")\n",
    "    texto=texto.replace(\"\\xc3\\x81\",\"Á\")\n",
    "    texto=texto.replace(\"\\xc3\\x89\",\"É\")\n",
    "    texto=texto.replace(\"\\xc3\\x8d\",\"Í\")\n",
    "    texto=texto.replace(\"\\xc3\\x93\",\"Ó\")\n",
    "    texto=texto.replace(\"\\xc3\\x9a\",\"Ú\")\n",
    "    texto=texto.replace(\"\\xc3±\",\"ñ\")\n",
    "    return(texto)\n",
    "\n",
    "def PreProcesar(textos):\n",
    "    texto_limpio = []\n",
    "    for texto in textos:  \n",
    "        texto = EliminarStopwords(texto.lower())    \n",
    "        texto = Lematizar(texto)     \n",
    "        texto = EliminaNumeroYPuntuacion(texto)      \n",
    "        if len(texto)!=0:\n",
    "          texto = regex.sub(' +', ' ', texto)\n",
    "          texto_limpio.append(texto)\n",
    "    return(texto_limpio)\n",
    "\n",
    "def EliminaNumeroYPuntuacion(oracion):\n",
    "    string_numeros = regex.sub(r'[\\”\\“\\¿\\°\\d+]','', oracion)\n",
    "    return ''.join(c for c in string_numeros if c not in punctuation)\n",
    "\n",
    "def Lematizar(oracion):\n",
    "   doc = nlp(oracion)\n",
    "   lemas = [token.lemma_ for token in doc]\n",
    "   return(\" \".join(lemas))  \n",
    "  \n",
    "def EliminarStopwords(oracion):\n",
    "    Tokens = Tokenizar(oracion)\n",
    "    oracion_filtrada = [word for word in Tokens if word not in STOP_WORDS]\n",
    "    return(\" \".join(oracion_filtrada))\n",
    "\n",
    "def Tokenizar(oracion):\n",
    "    doc = nlp(oracion)\n",
    "    tokens = [palabra.text for palabra in doc]\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYcMKpymSDjE"
   },
   "source": [
    "Ahora definimos la función **clustering(MatrizDocumentos,K)**, que realiza clustering K-Means a partir de una **Matriz de Documentos** generada  con el modelo TFxIDF y un número **K** de clusters y retorna los clusters creados. Esta corresponde una lista donde indica el número (ID) de cluster para cada documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26XuVE0JSk71"
   },
   "outputs": [],
   "source": [
    "def clustering(MatrizDocumentos,K):\n",
    "  modelo = KMeans(n_clusters=K)   \n",
    "  modelo.fit(MatrizDocumentos)        \n",
    "  return(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_ZALNfcSt4F"
   },
   "source": [
    "Luego, definimos la función **VisualizarClusters(clusters,docIDs,MatrizDocumentos)**, que toma los clusters generados previamente, los identificadores de documentos y la matriz de documentos, y visualiza los clusters en un mapa 2-dimensional. Con fines de visualización, se asignan diferentes colores a los clusters ccon un máximo de 5 clusters.\n",
    "\n",
    "Con el fin de gráficar los datos en 2 dimensiones, se aplica  escalamiento  multidimensional ([MDS](https://www.statisticshowto.com/multidimensional-scaling/)). Este toma distancia entre todos los pares de vectores de documentos, calcula la nueva escala de distancia  entre puntos, y luego toma las 2 primeras componentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBR5ebS9TeMn"
   },
   "outputs": [],
   "source": [
    "def VisualizarClusters(clusters,docIDs,MatrizDocumentos):\n",
    "    (x_nueva,y_nueva) = Escalar(MatrizDocumentos)\n",
    "    color_cluster = {0: '#1b9e77', 1: '#d95f02', \n",
    "                      2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
    "    nombre_cluster = {0: 'Cluster0', \n",
    "                      1: 'Cluster1', \n",
    "                      2: 'Cluster2', \n",
    "                      3: 'Cluster3', \n",
    "                      4: 'Cluster4'}\n",
    "    df = pd.DataFrame(dict(x=x_nueva,y=y_nueva,label=clusters,title=docIDs)) \n",
    "    grupos = df.groupby('label')\n",
    "    fig, ax = plt.subplots(figsize=(17, 9)) \n",
    "    for nombre, grupo in grupos:\n",
    "        ax.plot(grupo.x, grupo.y, marker='o', linestyle='', \n",
    "               label=nombre_cluster[nombre], color=color_cluster[nombre]) \n",
    "    ax.legend() \n",
    "    for i in range(len(df)):\n",
    "        ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['title'], size=8)  \n",
    "    plt.show() \n",
    "\n",
    "def Escalar(data_matrix):\n",
    "    dist = 1 - cosine_similarity(data_matrix)\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\")\n",
    "    pos = mds.fit_transform(dist)  \n",
    "    x, y = pos[:, 0], pos[:, 1]\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlED7KzVVZy2"
   },
   "source": [
    "Un aspecto importante en clustering K-Means de documentos es fijar el número adecuado de clusters a generar (*K*). Una forma de determinar el mejor *K*, es graficar el error de clustering (i.e., **Suma de distancias cuadradas o SSE**)  en función de cada valor de *K* posible que toma como máximo el número de documentos. Luego, aplicamos la \"*regla del codo*\" para determinar cuando se observa una baja en el SSE para quedarnos con su valor de *K* correspondiente.\n",
    "\n",
    "Para visualizar esto, utilizamos la función **MostrarError(MatrizDocumentos,MaxDoc)**, que muestra los  valores de error (SSE) de K-Means para diferentes valores de *K*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlxo1jYEVpo-"
   },
   "outputs": [],
   "source": [
    "def MostrarError(MatrizDocumentos,MaxDoc):\n",
    "    score = []  \n",
    "    valores_k = list(range(2, MaxDoc))  \n",
    "    for k in valores_k:\n",
    "       Clusters = clustering(MatrizDocumentos,K)\n",
    "       sse = Clusters.inertia_\n",
    "       score.append(sse)   \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(valores_k, score, '-o')\n",
    "    plt.xlabel(r'Número de clusters (K)')\n",
    "    plt.ylabel(\"Suma de distancias cuadradas (SSE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGJUavl4W5d8"
   },
   "source": [
    "Ejecutamos  nuestro programa principal, ajustando la ubicación del orpus e inicializando métodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulkqfTiMXAIm"
   },
   "outputs": [],
   "source": [
    "PATH = 'C:\\\\Users\\\\Usuario\\\\M6-Bootcamp-UDD\\\\CORPUS\\\\coronavirus\\\\'\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LZgk-qvXKhH"
   },
   "source": [
    "Ahora, creamos y preprocesamos nuestro corpus, y generamos nuestro modelo vectorial para los documentos (TFxIDF): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5pua4QDXbzZ"
   },
   "outputs": [],
   "source": [
    "(corpus,docID) = CrearCorpus(PATH)\n",
    "textos  = PreProcesar(corpus)\n",
    "CrearVSM(textos,\"mi_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68iVgmyyXgs9"
   },
   "source": [
    "Cargamos nuestro modelo vectorial de documentos, realizamos nuestra tarea de clustering, y visualizamos los clusters generados. Los identificadores de clusters se encuentran en la lista **modelo.labels_**.\n",
    "\n",
    "Por ahora, asumimos que sólo deseamos generar *K=4* clusters (numerados de 0 a 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "id": "PP-X0swNX1cd",
    "outputId": "96ec8c5f-46e6-43e9-ecc4-66b0f223448f"
   },
   "outputs": [],
   "source": [
    "(vectores, vocabulario) = CargarModelo(\"mi_tfidf\")\n",
    "K = 4    \n",
    "modelo = clustering(vectores,K)\n",
    "VisualizarClusters(modelo.labels_,docID,vectores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Htxn7A0Y3cJ"
   },
   "source": [
    "Opcionalmente, si queremos estar seguro de cuál debería ser el número óptimo de clusters (*K*), podemos mostrar el gráfico de SSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iULrN5B7WJIt",
    "outputId": "3759143a-5566-496a-eb57-6747ac49e841"
   },
   "outputs": [],
   "source": [
    "print(modelo.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LF4hdqykQND0",
    "outputId": "bc71bbde-7b4b-49ce-ac8c-9c2fbe22cecb"
   },
   "outputs": [],
   "source": [
    "MaxDoc = len(docID)\n",
    "MostrarError(vectores,MaxDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
