{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AdHBFgBirgT"
   },
   "source": [
    "**Ponte a prueba 1**\n",
    "\n",
    "Utiliza el siguiente texto:\n",
    "\n",
    "The customer is very important, the customer will be followed by the customer. Vivamus quis tortor feugiat how facilisis sad eu nor massa In front of the disease arc, the cartoon does not need the layer, the size or the wisdom. Curabitur needs to be read to put a lot of laughter. The life of football is a vestibule of concern. In a just and untimely investment, the wisdom of life is expected. Even the ultrices put the ugly and the easy. But from the mass who will finance the free cycle. Before him, first of all, in the throats of the hospital, to lay the beds of care and care; There is nothing to be said about the shooting of the dui. You don't have to worry about stress. But the sauce was pleasing to the palate. He is said to have lived in this street. And now the trigger.\n",
    "\n",
    "Realiza los procesos vistos hasta ahora, es decir:\n",
    "- Remover signos de puntuación\n",
    "- Eliminar palabras vacías\n",
    "- Convertir todas las palabras a minúsculas\n",
    "- Quitar números\n",
    "- Tokenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeEeCF7Yiw_h"
   },
   "outputs": [],
   "source": [
    "#Respuesta con comentarios para explicar el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_JxR6pKJMYz",
    "outputId": "bb164447-c230-4e1c-87ca-6733ac34915c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79N0LModH8ri",
    "outputId": "2c38c3b9-855c-4bd5-ad09-9d09d5af330b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer',\n",
       " 'important',\n",
       " 'customer',\n",
       " 'followed',\n",
       " 'customer',\n",
       " 'vivamus',\n",
       " 'quis',\n",
       " 'tortor',\n",
       " 'feugiat',\n",
       " 'facilisis',\n",
       " 'sad',\n",
       " 'eu',\n",
       " 'massa',\n",
       " 'front',\n",
       " 'disease',\n",
       " 'arc',\n",
       " 'cartoon',\n",
       " 'need',\n",
       " 'layer',\n",
       " 'size',\n",
       " 'wisdom',\n",
       " 'curabitur',\n",
       " 'needs',\n",
       " 'read',\n",
       " 'put',\n",
       " 'lot',\n",
       " 'laughter',\n",
       " 'life',\n",
       " 'football',\n",
       " 'vestibule',\n",
       " 'concern',\n",
       " 'untimely',\n",
       " 'investment',\n",
       " 'wisdom',\n",
       " 'life',\n",
       " 'expected',\n",
       " 'even',\n",
       " 'ultrices',\n",
       " 'put',\n",
       " 'ugly',\n",
       " 'easy',\n",
       " 'mass',\n",
       " 'finance',\n",
       " 'free',\n",
       " 'cycle',\n",
       " 'first',\n",
       " 'throats',\n",
       " 'hospital',\n",
       " 'lay',\n",
       " 'beds',\n",
       " 'care',\n",
       " 'care',\n",
       " 'nothing',\n",
       " 'said',\n",
       " 'shooting',\n",
       " 'dui',\n",
       " 'dont',\n",
       " 'worry',\n",
       " 'stress',\n",
       " 'sauce',\n",
       " 'pleasing',\n",
       " 'palate',\n",
       " 'said',\n",
       " 'lived',\n",
       " 'street',\n",
       " 'trigger']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Texto original\n",
    "text = (\"the customer is very important, the customer will be followed by the customer. \"\n",
    "       \"Vivamus quis tortor feugiat how facilisis sad eu nor massa In front of the disease arc, \"\n",
    "       \"the cartoon does not need the layer, the size or the wisdom. Curabitur needs to be read \"\n",
    "       \"to put a lot of laughter. The life of football is a vestibule of concern. In a just and \"\n",
    "       \"untimely investment, the wisdom of life is expected. Even the ultrices put the ugly and the easy. \"\n",
    "       \"But from the mass who will finance the free cycle. Before him, first of all, in the throats of the \"\n",
    "       \"hospital, to lay the beds of care and care; There is nothing to be said about the shooting of the dui. \"\n",
    "       \"You don't have to worry about stress. But the sauce was pleasing to the palate. He is said to have lived \"\n",
    "       \"in this street. And now the trigger.\")\n",
    "\n",
    "# 1. Remover signos de puntuación\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# 2. Convertir todas las palabras a minúsculas\n",
    "text = text.lower()\n",
    "\n",
    "# 3. Quitar números\n",
    "text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "# 4. Tokenizar\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# 5. Eliminar palabras vacías\n",
    "filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "filtered_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hmn0fGY8LqKm"
   },
   "source": [
    "**Ponte a prueba 2**\n",
    "\n",
    "Utiliza el siguiente texto:\n",
    "\n",
    "The customer is very important, the customer will be followed by the customer. Vivamus quis tortor feugiat how facilisis sad eu nor massa In front of the disease arc, the cartoon does not need the layer, the size or the wisdom. Curabitur needs to be read to put a lot of laughter. The life of football is a vestibule of concern. In a just and untimely investment, the wisdom of life is expected. Even the ultrices put the ugly and the easy. But from the mass who will finance the free cycle. Before him, first of all, in the throats of the hospital, to lay the beds of care and care; There is nothing to be said about the shooting of the dui. You don't have to worry about stress. But the sauce was pleasing to the palate. He is said to have lived in this street. And now the trigger.\n",
    "\n",
    "Realiza los procesos vistos hasta ahora, es decir:\n",
    "- Remover signos de puntuación\n",
    "- Eliminar palabras vacías\n",
    "- Convertir todas las palabras a minúsculas\n",
    "- Quitar números\n",
    "- Tokenizar\n",
    "- Stemming\n",
    "- Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLVpCrLwi_mS"
   },
   "outputs": [],
   "source": [
    "#Respuesta con comentarios para explicar el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFB1EOYrJRiU",
    "outputId": "22c6c9ea-5b50-4f6b-fd16-dca230addbf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stemmed_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 7. Lematización\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Nota: Se necesita un POS tagger para una lematización más precisa, pero aquí estamos asumiendo\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# que todas las palabras son sustantivos para simplificar el proceso.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m----> 5\u001b[0m lemmatized_tokens \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m stemmed_tokens]\n\u001b[0;32m      7\u001b[0m lemmatized_tokens\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stemmed_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Lematización\n",
    "# Nota: Se necesita un POS tagger para una lematización más precisa, pero aquí estamos asumiendo\n",
    "# que todas las palabras son sustantivos para simplificar el proceso.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdFeTXM7JUez",
    "outputId": "34a45aff-cb95-495f-d1a0-82597e9d1287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'custom',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'import',\n",
       " 'the',\n",
       " 'custom',\n",
       " 'will',\n",
       " 'be',\n",
       " 'follow',\n",
       " 'by',\n",
       " 'the',\n",
       " 'custom',\n",
       " 'vivamu',\n",
       " 'qui',\n",
       " 'tortor',\n",
       " 'feugiat',\n",
       " 'how',\n",
       " 'facilisi',\n",
       " 'sad',\n",
       " 'eu',\n",
       " 'nor',\n",
       " 'massa',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'the',\n",
       " 'diseas',\n",
       " 'arc',\n",
       " 'the',\n",
       " 'cartoon',\n",
       " 'doe',\n",
       " 'not',\n",
       " 'need',\n",
       " 'the',\n",
       " 'layer',\n",
       " 'the',\n",
       " 'size',\n",
       " 'or',\n",
       " 'the',\n",
       " 'wisdom',\n",
       " 'curabitur',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'read',\n",
       " 'to',\n",
       " 'put',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'laughter',\n",
       " 'the',\n",
       " 'life',\n",
       " 'of',\n",
       " 'footbal',\n",
       " 'is',\n",
       " 'a',\n",
       " 'vestibul',\n",
       " 'of',\n",
       " 'concern',\n",
       " 'in',\n",
       " 'a',\n",
       " 'just',\n",
       " 'and',\n",
       " 'untim',\n",
       " 'invest',\n",
       " 'the',\n",
       " 'wisdom',\n",
       " 'of',\n",
       " 'life',\n",
       " 'is',\n",
       " 'expect',\n",
       " 'even',\n",
       " 'the',\n",
       " 'ultric',\n",
       " 'put',\n",
       " 'the',\n",
       " 'ugli',\n",
       " 'and',\n",
       " 'the',\n",
       " 'easi',\n",
       " 'but',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " 'who',\n",
       " 'will',\n",
       " 'financ',\n",
       " 'the',\n",
       " 'free',\n",
       " 'cycl',\n",
       " 'befor',\n",
       " 'him',\n",
       " 'first',\n",
       " 'of',\n",
       " 'all',\n",
       " 'in',\n",
       " 'the',\n",
       " 'throat',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hospit',\n",
       " 'to',\n",
       " 'lay',\n",
       " 'the',\n",
       " 'bed',\n",
       " 'of',\n",
       " 'care',\n",
       " 'and',\n",
       " 'care',\n",
       " 'there',\n",
       " 'is',\n",
       " 'noth',\n",
       " 'to',\n",
       " 'be',\n",
       " 'said',\n",
       " 'about',\n",
       " 'the',\n",
       " 'shoot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'duo',\n",
       " 'you',\n",
       " 'dont',\n",
       " 'have',\n",
       " 'to',\n",
       " 'worri',\n",
       " 'about',\n",
       " 'stress',\n",
       " 'but',\n",
       " 'the',\n",
       " 'sauc',\n",
       " 'wa',\n",
       " 'plea',\n",
       " 'to',\n",
       " 'the',\n",
       " 'palat',\n",
       " 'he',\n",
       " 'is',\n",
       " 'said',\n",
       " 'to',\n",
       " 'have',\n",
       " 'live',\n",
       " 'in',\n",
       " 'thi',\n",
       " 'street',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'trigger']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Texto original\n",
    "text = (\"The customer is very important, the customer will be followed by the customer. \"\n",
    "       \"Vivamus quis tortor feugiat how facilisis sad eu nor massa In front of the disease arc, \"\n",
    "       \"the cartoon does not need the layer, the size or the wisdom. Curabitur needs to be read \"\n",
    "       \"to put a lot of laughter. The life of football is a vestibule of concern. In a just and \"\n",
    "       \"untimely investment, the wisdom of life is expected. Even the ultrices put the ugly and the easy. \"\n",
    "       \"But from the mass who will finance the free cycle. Before him, first of all, in the throats of the \"\n",
    "       \"hospital, to lay the beds of care and care; There is nothing to be said about the shooting of the dui. \"\n",
    "       \"You don't have to worry about stress. But the sauce was pleasing to the palate. He is said to have lived \"\n",
    "       \"in this street. And now the trigger.\")\n",
    "\n",
    "# 1. Remover signos de puntuación\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# 2. Convertir todas las palabras a minúsculas\n",
    "text = text.lower()\n",
    "\n",
    "# 3. Quitar números\n",
    "text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "# 4. Tokenizar\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# 5. Eliminar palabras vacías\n",
    "stopwords = [\n",
    "    # Aquí agregarías la lista básica de palabras vacías que te proporcioné anteriormente\n",
    "]\n",
    "filtered_tokens = [word for word in tokens if word not in stopwords]\n",
    "\n",
    "# 6. Stemización\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "# 7. Lematización\n",
    "# Nota: Se necesita un POS tagger para una lematización más precisa, pero aquí estamos asumiendo\n",
    "# que todas las palabras son sustantivos para simplificar el proceso.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrGC_FIMioad"
   },
   "source": [
    "**Reto semanal**\n",
    "\n",
    "Utilizan el siguiente dataset https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing/data y realiza las siguientes tareas:\n",
    "\n",
    "- Convertir todo el texto a minúsculas\n",
    "- Tokenizar el texto\n",
    "- Quitar signos de puntuación\n",
    "- Derivar o lematizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03i_10wrMGRY"
   },
   "outputs": [],
   "source": [
    "#Respuesta con comentarios para explicar el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbfXAlp6K5h0",
    "outputId": "a137bde0-46ef-4c6e-d4dd-0d5bb0c0d1f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRgZeO0LK1Mk"
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "jqKk3pIhKz6X",
    "outputId": "333f4ffb-2713-4e18-c8a6-f2a116a8d1a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-63f1ebe4-c227-4957-b46c-3c05da7dfe28\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f1ebe4-c227-4957-b46c-3c05da7dfe28')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-63f1ebe4-c227-4957-b46c-3c05da7dfe28 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-63f1ebe4-c227-4957-b46c-3c05da7dfe28');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d051e4f7-0409-4695-b5bf-5dc7f0872324\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d051e4f7-0409-4695-b5bf-5dc7f0872324')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d051e4f7-0409-4695-b5bf-5dc7f0872324 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer el dataset\n",
    "# Reemplaza por la ubicación del conjunto de datos en tu Google Drive\n",
    "df = pd.read_csv('/content/drive/MyDrive/Bootcamp Data Science/Datasets/sample.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset para tener una idea de su estructura\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmphqNS1LZDs"
   },
   "source": [
    "El dataset contiene tweets con varias columnas, como tweet_id, author_id, etc. La columna que nos interesa para el procesamiento de texto es \"text\", que contiene el contenido del tweet.\n",
    "\n",
    "Procederemos con el segundo paso: convertir todo el texto a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJZ4RP7dKz_O",
    "outputId": "202c9f37-88ee-4c0b-f9b0-7e22e4899bf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @applesupport causing the reply to be disregar...\n",
       "1    @105835 your business means a lot to us. pleas...\n",
       "2    @76328 i really hope you all change but i'm su...\n",
       "3    @105836 livechat is online at the moment - htt...\n",
       "4    @virgintrains see attached error message. i've...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir todo el texto a minúsculas\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# Mostrar las primeras filas del dataset después de la conversión\n",
    "df['text'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSt_qXptLcQu"
   },
   "source": [
    "El texto ha sido convertido a minúsculas.\n",
    "\n",
    "Ahora, procederemos con el tercer paso: tokenizar el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxgYzFcTLbaP",
    "outputId": "652cf12b-89ae-44f0-d4e5-1a4b75fce1ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [@, applesupport, causing, the, reply, to, be,...\n",
       "1    [@, 105835, your, business, means, a, lot, to,...\n",
       "2    [@, 76328, i, really, hope, you, all, change, ...\n",
       "3    [@, 105836, livechat, is, online, at, the, mom...\n",
       "4    [@, virgintrains, see, attached, error, messag...\n",
       "Name: tokenized_text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizar el texto\n",
    "df['tokenized_text'] = df['text'].apply(word_tokenize)\n",
    "\n",
    "# Mostrar las primeras filas del texto tokenizado\n",
    "df['tokenized_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMhspFQsLl1a"
   },
   "source": [
    "Quitar signos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80QqYLbVLf-A"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(tokens):\n",
    "    return [word for word in tokens if word not in string.punctuation]\n",
    "\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuj2Aw7RMMgZ"
   },
   "source": [
    "Derivar (stemming) o lematizar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qczHH_UxMEca"
   },
   "outputs": [],
   "source": [
    "# En este caso usaremos lematización. Si prefieres stemming, simplemente reemplaza esta parte.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_text'] = df['tokenized_text'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LQEYV8lMQus"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
